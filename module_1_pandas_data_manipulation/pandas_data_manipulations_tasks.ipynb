{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_column', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Leave that code unchanged, it is required for the server check!\n",
    "db = sqlite3.connect(os.environ.get(\"DB_PATH\") or 'database.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# You may load the data from SQL table directly to the Pandas dataframe as\n",
    "player_data = pd.read_sql(\"SELECT * FROM Player;\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id  player_api_id         player_name  player_fifa_api_id  \\\n0   1         505942  Aaron Appindangoye              218353   \n1   2         155782     Aaron Cresswell              189615   \n2   3         162549         Aaron Doran              186170   \n3   4          30572       Aaron Galindo              140161   \n4   5          23780        Aaron Hughes               17725   \n\n              birthday  height  weight  \n0  1992-02-29 00:00:00  182.88     187  \n1  1989-12-15 00:00:00  170.18     146  \n2  1991-05-13 00:00:00  170.18     163  \n3  1982-05-08 00:00:00  182.88     198  \n4  1979-11-08 00:00:00  182.88     154  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>player_api_id</th>\n      <th>player_name</th>\n      <th>player_fifa_api_id</th>\n      <th>birthday</th>\n      <th>height</th>\n      <th>weight</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>505942</td>\n      <td>Aaron Appindangoye</td>\n      <td>218353</td>\n      <td>1992-02-29 00:00:00</td>\n      <td>182.88</td>\n      <td>187</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>155782</td>\n      <td>Aaron Cresswell</td>\n      <td>189615</td>\n      <td>1989-12-15 00:00:00</td>\n      <td>170.18</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>162549</td>\n      <td>Aaron Doran</td>\n      <td>186170</td>\n      <td>1991-05-13 00:00:00</td>\n      <td>170.18</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>30572</td>\n      <td>Aaron Galindo</td>\n      <td>140161</td>\n      <td>1982-05-08 00:00:00</td>\n      <td>182.88</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>23780</td>\n      <td>Aaron Hughes</td>\n      <td>17725</td>\n      <td>1979-11-08 00:00:00</td>\n      <td>182.88</td>\n      <td>154</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "player_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 1 (0.25 point). \n",
    "# Calculate the number of players with a height between 180 and 190 inclusive\n",
    "\n",
    "players_180_190 = player_data[(player_data['height'] >= 180) & (player_data['height'] <= 190)].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(players_180_190, int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 2 (0.25 point). Calculate the number of players born in 1980.\n",
    "# Hint: you may want to cast your 'birthday' column to DateTime type by pandas.to_datetime\n",
    "\n",
    "player_data['birthday'] = pd.to_datetime(player_data['birthday'])\n",
    "players_1980 = player_data[(player_data['birthday'] >= '1980-01-01') \n",
    "                           & (player_data['birthday'] < '1981-01-01')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(players_1980, int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 3 (0.25 point). Make a list of the top 10 players with the highest weight sorted in descending order. \n",
    "# If there are several players with the same weight put them in the lexicographic order by name.\n",
    "\n",
    "df = player_data.sort_values(by=['weight', 'player_name'], ascending=[False, True])\n",
    "highest_players = df.head(10)['player_name'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(highest_players) == 10)\n",
    "assert(isinstance(highest_players, list))\n",
    "for i in range(10):\n",
    "    assert(isinstance(highest_players[i], str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 4 (0.5 point). Make a list of tuples containing years along with the number of players born in that year from 1980 up to 1990.\n",
    "# Structure example: [(1980, 123), (1981, 140) ..., (1990, 83)] -> There were born 123 players in 1980, there were born 140 players in 1981 and etc.\n",
    "\n",
    "player_data['birthday'] = pd.to_datetime(player_data['birthday'])\n",
    "df = player_data\n",
    "df1 = df.groupby([df['birthday'].dt.year]).agg({'count'})\n",
    "\n",
    "new_df = df1['player_name'].copy()\n",
    "df2 = new_df.loc['1980':'1990']\n",
    "years_born_players = list(df2.itertuples(index=True, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(years_born_players) == 11)\n",
    "assert(isinstance(years_born_players, list))\n",
    "for i in range(10):\n",
    "    assert(isinstance(years_born_players[i], tuple))\n",
    "    assert(isinstance(years_born_players[i][0], int))\n",
    "    assert(isinstance(years_born_players[i][1], int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 5 (0.5 point). Calculate the mean and the standard deviation of the players' height with the name Adriano.\n",
    "# Note: Name is represented by the first part of player_name.\n",
    "df = player_data.loc[(player_data['player_name'].str.startswith('Adriano')), \n",
    "                      ['player_name','height']]\n",
    "\n",
    "adriano_mean = df['height'].mean()\n",
    "adriano_std = df['height'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(adriano_mean, float))\n",
    "assert(isinstance(adriano_std, float))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 6 (0.75 point). How many players were born on each day of the week? Find the day of the week with the minimum number of players born.\n",
    "\n",
    "player_data['birthday'] = pd.to_datetime(player_data['birthday'])\n",
    "df = player_data\n",
    "df['weekday'] = df['birthday'].dt.day_name()\n",
    "day_counted = df.groupby('weekday').count()\n",
    "day_sorted = day_counted.sort_values(by='id')\n",
    "day_sorted['weekday'] = day_sorted.index\n",
    "dow_with_min_players_born = day_sorted.head()['weekday'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(dow_with_min_players_born, str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 7 (0.75 point). Find a league with the most matches in total. \n",
    "# If there are several leagues with the same amount of matches, take the first in the lexical order.\n",
    "match_data = pd.read_sql(\"SELECT id, league_id FROM Match;\", db)\n",
    "league_data = pd.read_sql(\"SELECT * FROM League;\", db)\n",
    "\n",
    "match_count_df = match_data.groupby('league_id').count()\n",
    "match_count_df.reset_index(inplace=True)\n",
    "match_count_df.rename(columns={'id': 'count'}, inplace=True)\n",
    "\n",
    "df = league_data.merge(match_count_df, left_on='id', right_on='league_id', how='inner')\n",
    "df = df.loc[df['count'] == 3040]\n",
    "df = df.sort_values(by='name').head()\n",
    "league_list = df.head()['name'].values.tolist()\n",
    "league_most_matches = league_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(league_most_matches, str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 8 (1.25 point). Find a player who participated in the largest number of matches during the whole match history. \n",
    "# Assign a player_name to the given variable\n",
    "\n",
    "match_df = pd.read_sql(\"SELECT id, home_player_1, home_player_2, home_player_3, home_player_4, home_player_5, home_player_6, home_player_7, home_player_8, home_player_9, home_player_10, home_player_11, away_player_1, away_player_2, away_player_3, away_player_4, away_player_5, away_player_6, away_player_7, away_player_8, away_player_9, away_player_10, away_player_11 FROM Match;\", db)\n",
    "player_df = pd.read_sql(\"SELECT player_api_id, player_name FROM Player;\", db)\n",
    "\n",
    "###\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_1 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_1'], ascending=True)\n",
    "match_df_sorted1['count_player1'] = match_df_sorted1['home_player_1'].map(match_df_sorted1['home_player_1'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_1', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count1 = df_drop_column.sort_values(by='home_player_1').set_index('home_player_1')\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_2 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_2'], ascending=True)\n",
    "match_df_sorted1['count_player2'] = match_df_sorted1['home_player_2'].map(match_df_sorted1['home_player_2'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_2', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count2 = df_drop_column.sort_values(by='home_player_2').set_index('home_player_2')\n",
    "result2 = match_count1.merge(match_count2, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_3 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_3'], ascending=True)\n",
    "match_df_sorted1['count_player3'] = match_df_sorted1['home_player_3'].map(match_df_sorted1['home_player_3'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_3', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count3 = df_drop_column.sort_values(by='home_player_3').set_index('home_player_3')\n",
    "result3 = result2.merge(match_count3, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_4 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_4'], ascending=True)\n",
    "match_df_sorted1['count_player4'] = match_df_sorted1['home_player_4'].map(match_df_sorted1['home_player_4'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_4', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count4 = df_drop_column.sort_values(by='home_player_4').set_index('home_player_4')\n",
    "result4 = result3.merge(match_count4, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_5 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_5'], ascending=True)\n",
    "match_df_sorted1['count_player5'] = match_df_sorted1['home_player_5'].map(match_df_sorted1['home_player_5'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_5', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count5 = df_drop_column.sort_values(by='home_player_5').set_index('home_player_5')\n",
    "result5 = result4.merge(match_count5, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_6 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_6'], ascending=True)\n",
    "match_df_sorted1['count_player6'] = match_df_sorted1['home_player_6'].map(match_df_sorted1['home_player_6'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_6', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count6 = df_drop_column.sort_values(by='home_player_6').set_index('home_player_6')\n",
    "result6 = result5.merge(match_count6, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_7 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_7'], ascending=True)\n",
    "match_df_sorted1['count_player7'] = match_df_sorted1['home_player_7'].map(match_df_sorted1['home_player_7'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_7', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count7 = df_drop_column.sort_values(by='home_player_7').set_index('home_player_7')\n",
    "result7 = result6.merge(match_count7, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_8 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_8'], ascending=True)\n",
    "match_df_sorted1['count_player8'] = match_df_sorted1['home_player_8'].map(match_df_sorted1['home_player_8'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_8', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count8 = df_drop_column.sort_values(by='home_player_8').set_index('home_player_8')\n",
    "result8 = result7.merge(match_count8, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_9 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_9'], ascending=True)\n",
    "match_df_sorted1['count_player9'] = match_df_sorted1['home_player_9'].map(match_df_sorted1['home_player_9'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_9', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count9 = df_drop_column.sort_values(by='home_player_9').set_index('home_player_9')\n",
    "result9 = result8.merge(match_count9, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_10 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_10'], ascending=True)\n",
    "match_df_sorted1['count_player10'] = match_df_sorted1['home_player_10'].map(match_df_sorted1['home_player_10'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_10', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count10 = df_drop_column.sort_values(by='home_player_10').set_index('home_player_10')\n",
    "result10 = result9.merge(match_count10, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, home_player_11 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['home_player_11'], ascending=True)\n",
    "match_df_sorted1['count_player11'] = match_df_sorted1['home_player_11'].map(match_df_sorted1['home_player_11'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('home_player_11', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count11 = df_drop_column.sort_values(by='home_player_11').set_index('home_player_11')\n",
    "result11 = result10.merge(match_count11, how='left', left_index=True, right_index=True)\n",
    "\n",
    "result11['total'] = result11.sum(axis=1)\n",
    "sum_matches_home = result11.drop(['count_player1', 'count_player2', 'count_player3', 'count_player4',\n",
    "                                  'count_player5', 'count_player6', 'count_player7', 'count_player8',\n",
    "                                  'count_player9', 'count_player10', 'count_player11'], axis=1)\n",
    "\n",
    "###\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_1 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_1'], ascending=True)\n",
    "match_df_sorted1['count_player1'] = match_df_sorted1['away_player_1'].map(match_df_sorted1['away_player_1'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_1', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count1 = df_drop_column.sort_values(by='away_player_1').set_index('away_player_1')\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_2 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_2'], ascending=True)\n",
    "match_df_sorted1['count_player2'] = match_df_sorted1['away_player_2'].map(match_df_sorted1['away_player_2'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_2', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count2 = df_drop_column.sort_values(by='away_player_2').set_index('away_player_2')\n",
    "result2 = match_count1.merge(match_count2, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_3 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_3'], ascending=True)\n",
    "match_df_sorted1['count_player3'] = match_df_sorted1['away_player_3'].map(match_df_sorted1['away_player_3'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_3', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count3 = df_drop_column.sort_values(by='away_player_3').set_index('away_player_3')\n",
    "result3 = result2.merge(match_count3, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_4 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_4'], ascending=True)\n",
    "match_df_sorted1['count_player4'] = match_df_sorted1['away_player_4'].map(match_df_sorted1['away_player_4'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_4', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count4 = df_drop_column.sort_values(by='away_player_4').set_index('away_player_4')\n",
    "result4 = result3.merge(match_count4, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_5 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_5'], ascending=True)\n",
    "match_df_sorted1['count_player5'] = match_df_sorted1['away_player_5'].map(match_df_sorted1['away_player_5'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_5', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count5 = df_drop_column.sort_values(by='away_player_5').set_index('away_player_5')\n",
    "result5 = result4.merge(match_count5, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_6 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_6'], ascending=True)\n",
    "match_df_sorted1['count_player6'] = match_df_sorted1['away_player_6'].map(match_df_sorted1['away_player_6'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_6', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count6 = df_drop_column.sort_values(by='away_player_6').set_index('away_player_6')\n",
    "result6 = result5.merge(match_count6, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_7 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_7'], ascending=True)\n",
    "match_df_sorted1['count_player7'] = match_df_sorted1['away_player_7'].map(match_df_sorted1['away_player_7'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_7', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count7 = df_drop_column.sort_values(by='away_player_7').set_index('away_player_7')\n",
    "result7 = result6.merge(match_count7, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_8 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_8'], ascending=True)\n",
    "match_df_sorted1['count_player8'] = match_df_sorted1['away_player_8'].map(match_df_sorted1['away_player_8'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_8', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count8 = df_drop_column.sort_values(by='away_player_8').set_index('away_player_8')\n",
    "result8 = result7.merge(match_count8, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_9 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_9'], ascending=True)\n",
    "match_df_sorted1['count_player9'] = match_df_sorted1['away_player_9'].map(match_df_sorted1['away_player_9'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_9', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count9 = df_drop_column.sort_values(by='away_player_9').set_index('away_player_9')\n",
    "result9 = result8.merge(match_count9, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_10 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_10'], ascending=True)\n",
    "match_df_sorted1['count_player10'] = match_df_sorted1['away_player_10'].map(match_df_sorted1['away_player_10'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_10', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count10 = df_drop_column.sort_values(by='away_player_10').set_index('away_player_10')\n",
    "result10 = result9.merge(match_count10, how='left', left_index=True, right_index=True)\n",
    "\n",
    "match_df1 = pd.read_sql(\"SELECT id, away_player_11 FROM Match;\", db)\n",
    "match_df_sorted1 = match_df1.sort_values(by=['away_player_11'], ascending=True)\n",
    "match_df_sorted1['count_player11'] = match_df_sorted1['away_player_11'].map(match_df_sorted1['away_player_11'].value_counts())\n",
    "df_drop_na = match_df_sorted1.dropna()\n",
    "df_drop_dupl = df_drop_na.copy()\n",
    "df_drop_dupl.drop_duplicates('away_player_11', inplace = True)\n",
    "df_drop_column = df_drop_dupl.drop(['id'], axis=1)\n",
    "match_count11 = df_drop_column.sort_values(by='away_player_11').set_index('away_player_11')\n",
    "result11 = result10.merge(match_count11, how='left', left_index=True, right_index=True)\n",
    "\n",
    "result11['total'] = result11.sum(axis=1)\n",
    "sum_matches_away = result11.drop(['count_player1', 'count_player2', 'count_player3', 'count_player4',\n",
    "                                  'count_player5', 'count_player6', 'count_player7', 'count_player8',\n",
    "                                  'count_player9', 'count_player10', 'count_player11'], axis=1)\n",
    "\n",
    "###\n",
    "sum_matches = sum_matches_away.merge(sum_matches_home, how='left', left_index=True, right_index=True)\n",
    "sum_matches['sum'] = sum_matches.sum(axis=1)\n",
    "sum_matches.sort_values(by='sum', inplace=True, ascending=False)\n",
    "\n",
    "sum_matches['player_id'] = sum_matches.index\n",
    "max_matches_player_id = sum_matches.head()['player_id'].values.tolist()[0]\n",
    "\n",
    "player_df_data = player_df[player_df['player_api_id'] == max_matches_player_id].head()\n",
    "max_matches_player = player_df_data.head()['player_name'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(max_matches_player, str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 9 (1.5 point). List top-5 tuples of most correlated player's characteristics in the descending order of the absolute Pearson's coefficient value.\n",
    "\n",
    "# Note 1: Players characteristics are all the columns in Player_Attributes table except [id, player_fifa_api_id, player_api_id, date, preferred_foot, attacking_work_rate, defensive_work_rate]).\n",
    "# Note 2: Exclude duplicated pairs from the list. E.g. ('gk_handling', 'gk_reflexes') and ('gk_reflexes', 'gk_handling') are duplicates, leave just one of them in the resulting list.\n",
    "\n",
    "# Hint: You may use dataframe.corr() for calculating pairwise Pearson correlation.\n",
    "\n",
    "player_charact = pd.read_sql(\"SELECT * FROM Player_Attributes;\", db)\n",
    "player_charact = player_charact.drop(['id', 'player_fifa_api_id', 'player_api_id', 'date', 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate'], axis=1)\n",
    "\n",
    "correlation_matrix = player_charact.corr()\n",
    "\n",
    "def get_redundant_pairs(df):\n",
    "    pairs_to_drop = set()\n",
    "    cols = df.columns\n",
    "    for i in range(0, df.shape[1]):\n",
    "        for j in range(0, i+1):\n",
    "            pairs_to_drop.add((cols[i], cols[j]))\n",
    "    return pairs_to_drop\n",
    "\n",
    "def get_top_abs_correlations(df, n):\n",
    "    au_corr = df.corr().abs().unstack()\n",
    "    labels_to_drop = get_redundant_pairs(df)\n",
    "    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n",
    "    return au_corr[0:n]\n",
    "\n",
    "top_5 = get_top_abs_correlations(player_charact, 5)\n",
    "top_correlated_features = top_5.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(top_correlated_features) == 5)\n",
    "assert(isinstance(top_correlated_features, list))\n",
    "for i in range(5):\n",
    "    assert(isinstance(top_correlated_features[i], tuple))\n",
    "    assert(isinstance(top_correlated_features[i][0], str))\n",
    "    assert(isinstance(top_correlated_features[i][1], str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 10 (2 points). Find top-5 most similar players to Neymar whose names are given. The similarity is measured as Euclidean distance between vectors of players' characteristics (described in the task above). Put their names in a vector in ascending order by Euclidean distance and sorted by player_name if the distance is the same\n",
    "# Note 1: There are many records for some players in the Player_Attributes table. You need to take the freshest data (characteristics with the most recent date).\n",
    "# Note 2: Use pure values of the characteristics even if you are aware of such preprocessing technics as normalization.\n",
    "# Note 3: Please avoid using any built-in methods for calculating the Euclidean distance between vectors, think about implementing your own.\n",
    "\n",
    "import numpy as np\n",
    "player = pd.read_sql(\"SELECT player_api_id, player_name FROM Player;\", db)\n",
    "player_charact = pd.read_sql(\"SELECT * FROM Player_Attributes;\", db)\n",
    "player_charact = player_charact.drop(['id', 'player_fifa_api_id', 'preferred_foot', 'attacking_work_rate', 'defensive_work_rate'], axis=1)\n",
    "cols = ['overall_rating','potential', 'crossing', 'finishing', 'heading_accuracy',\n",
    "                         'short_passing', 'volleys', 'dribbling', 'curve', 'free_kick_accuracy', 'long_passing',\n",
    "                         'ball_control', 'acceleration', 'sprint_speed', 'agility', 'reactions', 'balance',\n",
    "                         'shot_power', 'jumping', 'stamina', 'strength', 'long_shots', 'aggression', 'interceptions',\n",
    "                         'positioning', 'vision', 'penalties', 'marking', 'standing_tackle', 'sliding_tackle',\n",
    "                         'gk_diving', 'gk_handling', 'gk_kicking', 'gk_positioning', 'gk_reflexes']\n",
    "\n",
    "player_charact = player_charact.sort_values(by=['player_api_id', 'date'], ascending=[False, False])\n",
    "player_charact_result = player_charact.groupby('player_api_id').first().reset_index()\n",
    "\n",
    "neymar_charact = player_charact_result[player_charact_result['player_api_id'] == 19533].head()\n",
    "\n",
    "def euclidean_dist(player_charact_result, neymar_charact, cols):\n",
    "    return np.linalg.norm(player_charact_result[cols].values - neymar_charact[cols].values,\n",
    "                          axis=1)\n",
    "\n",
    "euclid_array = euclidean_dist(player_charact_result, neymar_charact, cols)\n",
    "player_charact_result['euclidean_dist'] = pd.Series(euclid_array)\n",
    "euclid_rate = player_charact_result.drop(cols, axis=1)\n",
    "euclid_rate.sort_values(by='euclidean_dist', inplace=True)\n",
    "euclid_rate_top5 = euclid_rate.iloc[1:6]\n",
    "\n",
    "player_names = pd.merge(euclid_rate_top5, player, on='player_api_id')\n",
    "neymar_similarities = player_names.head()['player_name'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(len(neymar_similarities) == 5)\n",
    "assert(isinstance(neymar_similarities, list))\n",
    "for i in range(5):\n",
    "    assert(isinstance(neymar_similarities[i], str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 11 (1 point). Calculate the number of home matches played by the Borussia Dortmund team \n",
    "# in Germany 1. Bundesliga in season 2008/2009\n",
    "match_df = pd.read_sql(\"SELECT league_id, home_team_api_id, season FROM Match;\", db)\n",
    "league_df = pd.read_sql(\"SELECT id, name FROM League;\", db)\n",
    "team_df = pd.read_sql(\"SELECT team_api_id, team_long_name FROM Team;\", db)\n",
    "\n",
    "team_name = team_df[team_df['team_long_name'] == 'Borussia Dortmund']\n",
    "team_id = team_name.head()['team_api_id'].values.tolist()[0]\n",
    "\n",
    "league_name = league_df[league_df['name'] == 'Germany 1. Bundesliga']\n",
    "league_id = league_name.head()['id'].values.tolist()[0]\n",
    "\n",
    "season_id = '2008/2009'\n",
    "\n",
    "matches = match_df[(match_df['league_id'] == league_id) & \n",
    "                   (match_df['home_team_api_id'] == team_id) &\n",
    "                   (match_df['season'] == season_id)]\n",
    "\n",
    "borussia_bundesliga_2008_2009_matches = matches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(borussia_bundesliga_2008_2009_matches, int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 12 (1 point). Find a team having the most matches (both home and away!) in the Germany 1. Bundesliga in 2008/2009 season. Return number of matches.\n",
    "match_df = pd.read_sql(\"SELECT league_id, home_team_api_id, away_team_api_id, season FROM Match;\", db)\n",
    "league_df = pd.read_sql(\"SELECT id, name FROM League;\", db)\n",
    "team_df = pd.read_sql(\"SELECT team_api_id, team_long_name FROM Team;\", db)\n",
    "\n",
    "league_name = league_df[league_df['name'] == 'Germany 1. Bundesliga']\n",
    "league_id = league_name.head()['id'].values.tolist()[0]\n",
    "\n",
    "season_id = '2008/2009'\n",
    "\n",
    "all_matches = match_df[(match_df['league_id'] == league_id) & \n",
    "                       (match_df['season'] == season_id)]\n",
    "\n",
    "home_matches = all_matches.groupby('home_team_api_id').count().sort_values(by='league_id')\n",
    "guest_matches = all_matches.groupby('away_team_api_id').count().sort_values(by='league_id')\n",
    "\n",
    "home_matches_count = home_matches.head(10)['league_id'].values.tolist()[0]\n",
    "guest_matches_count = guest_matches.head(10)['league_id'].values.tolist()[0]\n",
    "team_most_matches_bundesliga_2008_2009 = home_matches_count + guest_matches_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(team_most_matches_bundesliga_2008_2009, int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 13 (1 point). Count total number of Arsenal matches (both home and away!) in the 2015/2016 season \n",
    "# which they have won.\n",
    "# Note: Winning a game means scoring more goals than an opponent.\n",
    "import numpy as np\n",
    "\n",
    "match_df = pd.read_sql(\"SELECT home_team_api_id, away_team_api_id, season, home_team_goal, away_team_goal FROM Match;\", db)\n",
    "league_df = pd.read_sql(\"SELECT id, name FROM League;\", db)\n",
    "team_df = pd.read_sql(\"SELECT team_api_id, team_long_name FROM Team;\", db)\n",
    "\n",
    "team_name = team_df[team_df['team_long_name'] == 'Arsenal']\n",
    "team_id = team_name.head()['team_api_id'].values.tolist()[0]\n",
    "\n",
    "season_id = '2015/2016'\n",
    "\n",
    "home_matches = match_df[((match_df['home_team_api_id']) == team_id) &\n",
    "                         (match_df['season'] == season_id)]\n",
    "away_matches = match_df[((match_df['away_team_api_id']) == team_id) &\n",
    "                         (match_df['season'] == season_id)]\n",
    "\n",
    "home_matches_results = home_matches.copy()\n",
    "away_matches_results = away_matches.copy()\n",
    "\n",
    "conditions = [home_matches_results['home_team_goal'] > home_matches_results['away_team_goal'], \n",
    "              home_matches_results['home_team_goal'] < home_matches_results['away_team_goal']]\n",
    "choices = ['win', 'loose']\n",
    "home_matches_results['result'] = np.select(conditions, choices, default='tie')\n",
    "\n",
    "conditions = [away_matches_results['home_team_goal'] < away_matches_results['away_team_goal'], \n",
    "              away_matches_results['home_team_goal'] > away_matches_results['away_team_goal']]\n",
    "choices = ['win', 'loose']\n",
    "away_matches_results['result'] = np.select(conditions, choices, default='tie')\n",
    "\n",
    "won_home_matches = home_matches_results[home_matches_results['result'] == 'win']\n",
    "won_away_matches = away_matches_results[away_matches_results['result'] == 'win']\n",
    "\n",
    "won_home_matches_count = won_home_matches.shape[0]\n",
    "won_away_matches_count = won_away_matches.shape[0]\n",
    "\n",
    "arsenal_won_matches_2015_2016 = won_home_matches_count + won_away_matches_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(arsenal_won_matches_2015_2016, int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Task 14 (2 points). Find a team with the highest win rate in the 2015/2016 season. \n",
    "# Win rate means won matches / all matches. \n",
    "# If there are several teams with the highest win rate return the first by name in lexical order\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "match_df = pd.read_sql(\"SELECT league_id, home_team_api_id, away_team_api_id, season, home_team_goal, away_team_goal FROM Match;\", db)\n",
    "league_df = pd.read_sql(\"SELECT id, name FROM League;\", db)\n",
    "team_df = pd.read_sql(\"SELECT team_api_id, team_long_name FROM Team;\", db)\n",
    "\n",
    "season_id = '2015/2016'\n",
    "all_matches = match_df[(match_df['season'] == season_id)]\n",
    "\n",
    "matches_results = all_matches.copy()\n",
    "\n",
    "conditions = [matches_results['home_team_goal'] > matches_results['away_team_goal'], \n",
    "              matches_results['home_team_goal'] < matches_results['away_team_goal']]\n",
    "choices = ['win', 'loss']\n",
    "matches_results['result'] = np.select(conditions, choices, default='tie')\n",
    "\n",
    "matches_results['home_matches_count'] = matches_results.groupby(['home_team_api_id'])['home_team_goal'].transform('count')\n",
    "matches_results['away_matches_count'] = matches_results.groupby(['away_team_api_id'])['away_team_goal'].transform('count')\n",
    "matches_results['matches_count'] = matches_results['home_matches_count'] + matches_results['away_matches_count']\n",
    "matches_count_df = matches_results.drop(columns=['home_matches_count', 'away_matches_count'])\n",
    "\n",
    "win_matches_count = matches_count_df[matches_count_df['result'] == 'win']\n",
    "# win_matches_count\n",
    "\n",
    "win_home_count = win_matches_count.copy()\n",
    "win_home_count['home_matches_win'] = win_home_count.groupby(['home_team_api_id'])['result'].transform('count')\n",
    "win_home_count['away_matches_count'] = win_home_count.groupby(['away_team_api_id'])['result'].transform('count')\n",
    "win_home_count['win_matches_count'] = win_home_count['home_matches_win'] + win_home_count['away_matches_count']\n",
    "win_home_count = win_home_count.drop(columns=['home_matches_win', 'away_matches_count'])\n",
    "win_home_count['win_ratio'] = win_home_count['win_matches_count'] / win_home_count['matches_count']\n",
    "\n",
    "win_home_count.sort_values(by='win_ratio', inplace=True, ascending=False)\n",
    "\n",
    "best_team_id = win_home_count.head(10)['home_team_api_id'].values.tolist()[0]\n",
    "\n",
    "team_highest_winrate_2015_2016 = team_df[team_df['team_api_id'] == best_team_id].values.tolist()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(team_highest_winrate_2015_2016, str))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "18"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 33
    }
   ],
   "source": [
    "# Task 15 (2 points). Determine the team with the maximum days' gap between matches \n",
    "# in England Premier League 2010/2011 season. Return number of days in that gap.\n",
    "# Note: a gap means the number of days between two consecutive matches of the same team.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "match_df = pd.read_sql(\"SELECT league_id, date, home_team_api_id, away_team_api_id, season FROM Match;\", db)\n",
    "league_df = pd.read_sql(\"SELECT id, name FROM League;\", db)\n",
    "team_df = pd.read_sql(\"SELECT team_api_id, team_long_name FROM Team;\", db)\n",
    "\n",
    "league_name = league_df[league_df['name'] == 'England Premier League']\n",
    "league_id = league_name.head()['id'].values.tolist()[0]\n",
    "\n",
    "season_id = '2010/2011'\n",
    "\n",
    "matches = match_df[(match_df['league_id'] == league_id) &\n",
    "                   (match_df['season'] == season_id)]\n",
    "# matches\n",
    "home_matches = pd.DataFrame([matches.home_team_api_id, matches.date]).transpose()\n",
    "home_matches = home_matches.reset_index(drop=True)\n",
    "home_matches = home_matches.rename(columns={'home_team_api_id': 'team_id', 'date': 'date'})\n",
    "\n",
    "away_matches = pd.DataFrame([matches.away_team_api_id, matches.date]).transpose()\n",
    "away_matches = away_matches.reset_index(drop=True)\n",
    "away_matches = away_matches.rename(columns={'away_team_api_id': 'team_id', 'date': 'date'})\n",
    "\n",
    "all_matches = pd.concat([home_matches, away_matches])\n",
    "all_matches.sort_values(by='team_id', inplace=True)\n",
    "all_matches['date'] = pd.to_datetime(all_matches['date'])\n",
    "all_matches = all_matches.sort_values(by=['team_id', 'date'], ascending=[True, False])\n",
    "all_matches = all_matches.reset_index(drop=True)\n",
    "\n",
    "cols = ['date']\n",
    "all_matches['gap'] = all_matches.groupby('team_id')[cols].diff(-1)\n",
    "\n",
    "all_matches = all_matches.sort_values(by=['gap'], ascending=[False])\n",
    "all_matches['gap_in_days'] = all_matches['gap'].astype('timedelta64[D]')\n",
    "\n",
    "all_matches['gap_in_days'] = all_matches['gap_in_days'].fillna(0).astype(np.int64)\n",
    "\n",
    "highest_gap_england_2010_2011 = all_matches.head()['gap_in_days'].values.tolist()[0]\n",
    "highest_gap_england_2010_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "assert(isinstance(highest_gap_england_2010_2011, int))\n",
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "with open('student_answers.txt', 'w') as file:\n",
    "    file.write(f\"{players_180_190}\\n\")\n",
    "    file.write(f\"{players_1980}\\n\")\n",
    "    file.write(f\"{highest_players}\\n\")\n",
    "    file.write(f\"{years_born_players}\\n\")\n",
    "    file.write(f\"{round(adriano_mean, 3)} {round(adriano_std, 3)}\\n\")\n",
    "    file.write(f\"{dow_with_min_players_born}\\n\")\n",
    "    file.write(f\"{league_most_matches}\\n\")\n",
    "    file.write(f\"{max_matches_player}\\n\")\n",
    "    file.write(f\"{';'.join(['%s,%s' % tup for tup in top_correlated_features])};\\n\")\n",
    "    file.write(f\"{neymar_similarities}\\n\")\n",
    "    file.write(f\"{borussia_bundesliga_2008_2009_matches}\\n\")\n",
    "    file.write(f\"{team_most_matches_bundesliga_2008_2009}\\n\")\n",
    "    file.write(f\"{arsenal_won_matches_2015_2016}\\n\")\n",
    "    file.write(f\"{team_highest_winrate_2015_2016}\\n\")\n",
    "    file.write(f\"{highest_gap_england_2010_2011}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}